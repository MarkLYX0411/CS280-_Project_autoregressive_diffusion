{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "397d24eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from Unet import *\n",
    "from typing import *\n",
    "from train_utils import *\n",
    "import matplotlib as plt\n",
    "from tqdm import tqdm\n",
    "from dataset import QuickDrawDataset\n",
    "from GRU import HistoryEncoder\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46bac363",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/yujunwei/CS280-_Project_autoregressive_diffusuon/quickdraw_1k5_apple_cat.npz'\n",
    "val_dataset = QuickDrawDataset(data_path, split='valid')\n",
    "train_dataset = QuickDrawDataset(data_path, split='train')\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1,  # 在这里设置批处理大小\n",
    "    shuffle=True,\n",
    "    num_workers=10,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "# val_loader = torch.utils.data.DataLoader(\n",
    "#     val_dataset,\n",
    "#     batch_size=8,  # 同上\n",
    "#     shuffle=False,\n",
    "#     num_workers=2,\n",
    "#     pin_memory=True if torch.cuda.is_available() else False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49010eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HistoryEncoder(\n",
       "  (cnn): ConvEncoder(\n",
       "    (backbone): Sequential(\n",
       "      (0): Conv2d(12, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "      (2): SiLU()\n",
       "      (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (4): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "      (5): SiLU()\n",
       "      (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (7): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "      (8): SiLU()\n",
       "      (9): Conv2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (10): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "      (11): SiLU()\n",
       "    )\n",
       "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  )\n",
       "  (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (gru): GRU(128, 128, num_layers=2, batch_first=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
    "model = FlowMatching(UNet(1, 32, 32), GRU=HistoryEncoder(in_frames=12), num_ts=100)\n",
    "checkpoint = torch.load(\"/home/yujunwei/CS280-_Project_autoregressive_diffusuon/checkpoints_0505_64_resolution_32_unet_1k/model_20.pth\", map_location=device)\n",
    "model.load_state_dict(checkpoint)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "label = torch.nn.functional.one_hot(torch.tensor(2), num_classes=10).float().unsqueeze(0).to(device)\n",
    "\n",
    "model.unet.to(device)\n",
    "model.GRU.to(device)\n",
    "\n",
    "# x_p = torch.zeros(1, 12, 1, 256, 256).to(device)\n",
    "# video = model.autoregressive_sample(c=label, autoregressive_steps=5, img_wh=[256, 256], x_p=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74cf19bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters by layer:\n",
      "conv_1: 12,992 parameters\n",
      "down_1: 28,128 parameters\n",
      "down_2: 93,120 parameters\n",
      "down_3: 111,552 parameters\n",
      "down_4: 370,560 parameters\n",
      "after_GRU: 1,056,768 parameters\n",
      "up_1: 894,848 parameters\n",
      "up_2: 632,704 parameters\n",
      "up_3: 224,192 parameters\n",
      "up_4: 158,656 parameters\n",
      "final_conv: 21,932 parameters\n",
      "timeembed_1: 16,768 parameters\n",
      "timeembed_2: 16,768 parameters\n",
      "classembed_1: 17,920 parameters\n",
      "classembed_2: 17,920 parameters\n",
      "\n",
      "Total trainable parameters: 3,674,828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'conv_1': 12992,\n",
       " 'down_1': 28128,\n",
       " 'down_2': 93120,\n",
       " 'down_3': 111552,\n",
       " 'down_4': 370560,\n",
       " 'after_GRU': 1056768,\n",
       " 'up_1': 894848,\n",
       " 'up_2': 632704,\n",
       " 'up_3': 224192,\n",
       " 'up_4': 158656,\n",
       " 'final_conv': 21932,\n",
       " 'timeembed_1': 16768,\n",
       " 'timeembed_2': 16768,\n",
       " 'classembed_1': 17920,\n",
       " 'classembed_2': 17920}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters_by_layer(model):\n",
    "    \"\"\"Count parameters for each layer in the model.\"\"\"\n",
    "    param_counts = {}\n",
    "    total_params = 0\n",
    "    \n",
    "    # 遍历所有命名参数\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            # 提取层名\n",
    "            layer_name = name.split('.')[0] if '.' in name else name\n",
    "            \n",
    "            # 计算参数数量\n",
    "            param_count = param.numel()\n",
    "            \n",
    "            # 更新层参数计数\n",
    "            if layer_name in param_counts:\n",
    "                param_counts[layer_name] += param_count\n",
    "            else:\n",
    "                param_counts[layer_name] = param_count\n",
    "                \n",
    "            total_params += param_count\n",
    "    \n",
    "    # 打印每一层的参数数量\n",
    "    print(\"Parameters by layer:\")\n",
    "    for layer_name, count in param_counts.items():\n",
    "        print(f\"{layer_name}: {count:,} parameters\")\n",
    "    \n",
    "    print(f\"\\nTotal trainable parameters: {total_params:,}\")\n",
    "    \n",
    "    return param_counts\n",
    "\n",
    "# 使用方法\n",
    "count_parameters_by_layer(model.unet)\n",
    "\n",
    "# by reducing the resolution to 64 x 64: curr_param = 123437132\n",
    "# with hidden_dim = 32, we have 36713068 parameters\n",
    "# by removing the after_gru MLP: 32510572"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41cddb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HistoryEncoder(\n",
       "  (cnn): ConvEncoder(\n",
       "    (backbone): Sequential(\n",
       "      (0): Conv2d(12, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "      (2): SiLU()\n",
       "      (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (4): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "      (5): SiLU()\n",
       "      (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (7): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "      (8): SiLU()\n",
       "      (9): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (10): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "      (11): SiLU()\n",
       "    )\n",
       "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  )\n",
       "  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (gru): GRU(512, 512, num_layers=2, batch_first=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
    "model_2 = FlowMatching(UNet(1, 64, 64), GRU=HistoryEncoder(in_frames=12))\n",
    "checkpoint = torch.load(\"/home/yujunwei/CS280-_Project_autoregressive_diffusuon/checkpoints_0503_apple_update_gru/model_5.pth\", map_location=device)\n",
    "model_2.load_state_dict(checkpoint)\n",
    "model_2 = model_2.to(device)\n",
    "model_2.eval()\n",
    "label = torch.nn.functional.one_hot(torch.tensor(2), num_classes=10).float().unsqueeze(0).to(device)\n",
    "\n",
    "model_2.unet.to(device)\n",
    "model_2.GRU.to(device)\n",
    "\n",
    "# x_p = torch.zeros(1, 12, 1, 256, 256).to(device)\n",
    "# video = model.autoregressive_sample(c=label, autoregressive_steps=5, img_wh=[256, 256], x_p=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09633e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn.backbone.0.weight\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0447,  0.0104,  0.0721],\n",
      "          [-0.0283, -0.0678, -0.0100],\n",
      "          [-0.0279,  0.0455, -0.0571]],\n",
      "\n",
      "         [[ 0.0681, -0.0854, -0.0304],\n",
      "          [-0.0376, -0.0608, -0.0927],\n",
      "          [-0.0465, -0.0049,  0.0798]],\n",
      "\n",
      "         [[ 0.0043, -0.0599,  0.0896],\n",
      "          [-0.0052,  0.0885,  0.0523],\n",
      "          [ 0.0194,  0.0474, -0.0065]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0657,  0.0028,  0.0623],\n",
      "          [ 0.0245,  0.0492, -0.0036],\n",
      "          [-0.0580, -0.0280,  0.0738]],\n",
      "\n",
      "         [[ 0.0411, -0.0069,  0.0381],\n",
      "          [ 0.0864,  0.0450,  0.0551],\n",
      "          [-0.0751,  0.0383, -0.0339]],\n",
      "\n",
      "         [[-0.0180,  0.0423,  0.0873],\n",
      "          [-0.0030,  0.0411, -0.0252],\n",
      "          [ 0.0903, -0.0617,  0.0810]]],\n",
      "\n",
      "\n",
      "        [[[-0.0446, -0.0735, -0.0365],\n",
      "          [ 0.0509, -0.0259,  0.0773],\n",
      "          [-0.0188,  0.0720,  0.0897]],\n",
      "\n",
      "         [[ 0.0633, -0.0219,  0.0059],\n",
      "          [-0.0816, -0.0466,  0.0381],\n",
      "          [ 0.0571, -0.0208, -0.0252]],\n",
      "\n",
      "         [[ 0.0063,  0.0226,  0.0226],\n",
      "          [ 0.0476, -0.0718,  0.0148],\n",
      "          [-0.0562, -0.0744,  0.0323]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0327, -0.0969, -0.0950],\n",
      "          [-0.0193, -0.0735,  0.0909],\n",
      "          [ 0.0198, -0.0284,  0.0426]],\n",
      "\n",
      "         [[-0.0821,  0.0678,  0.0507],\n",
      "          [-0.0223,  0.0695, -0.0316],\n",
      "          [-0.0663,  0.0369, -0.0514]],\n",
      "\n",
      "         [[-0.0242, -0.0580, -0.0479],\n",
      "          [ 0.0640,  0.0007,  0.0189],\n",
      "          [-0.0478,  0.0666,  0.0632]]],\n",
      "\n",
      "\n",
      "        [[[-0.0932,  0.0630,  0.0320],\n",
      "          [ 0.0305, -0.0442,  0.0892],\n",
      "          [-0.0248, -0.0418, -0.0052]],\n",
      "\n",
      "         [[-0.0174, -0.0375, -0.0072],\n",
      "          [ 0.0421, -0.0641, -0.0203],\n",
      "          [ 0.0842, -0.0664, -0.0752]],\n",
      "\n",
      "         [[ 0.0570, -0.1022,  0.0685],\n",
      "          [-0.0556, -0.0372, -0.0781],\n",
      "          [ 0.0702, -0.0081, -0.0973]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0129, -0.0467,  0.0827],\n",
      "          [-0.0355,  0.0463,  0.0098],\n",
      "          [-0.0033, -0.0600,  0.0367]],\n",
      "\n",
      "         [[ 0.0832, -0.0022,  0.0779],\n",
      "          [ 0.0806,  0.0068,  0.0555],\n",
      "          [ 0.0024, -0.0735, -0.0820]],\n",
      "\n",
      "         [[-0.0978,  0.0164,  0.0871],\n",
      "          [-0.0788,  0.0294, -0.0309],\n",
      "          [ 0.0348,  0.0885,  0.0589]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0851,  0.0770,  0.0631],\n",
      "          [ 0.0153, -0.0115,  0.0369],\n",
      "          [-0.0823,  0.0035,  0.0258]],\n",
      "\n",
      "         [[ 0.0262, -0.0904,  0.0072],\n",
      "          [ 0.0746, -0.0078, -0.0615],\n",
      "          [ 0.0318,  0.0264, -0.0667]],\n",
      "\n",
      "         [[-0.0524, -0.0645,  0.0336],\n",
      "          [ 0.0459, -0.0834, -0.0296],\n",
      "          [ 0.0241, -0.0046, -0.0771]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0308, -0.0334, -0.0939],\n",
      "          [ 0.0856, -0.0606, -0.0897],\n",
      "          [ 0.0682, -0.0330, -0.0340]],\n",
      "\n",
      "         [[-0.0377,  0.0543,  0.0049],\n",
      "          [ 0.0347, -0.0722,  0.0256],\n",
      "          [ 0.0473, -0.0643, -0.0891]],\n",
      "\n",
      "         [[ 0.0749, -0.0124, -0.0256],\n",
      "          [ 0.0200, -0.0058,  0.0924],\n",
      "          [ 0.0421, -0.0118, -0.0657]]],\n",
      "\n",
      "\n",
      "        [[[-0.0393,  0.0735, -0.0121],\n",
      "          [ 0.0650, -0.0338,  0.0536],\n",
      "          [-0.0435, -0.0687,  0.0352]],\n",
      "\n",
      "         [[ 0.0660, -0.0656, -0.0873],\n",
      "          [-0.0275,  0.0722,  0.0217],\n",
      "          [ 0.0137,  0.0366,  0.0264]],\n",
      "\n",
      "         [[ 0.0835, -0.0458, -0.0067],\n",
      "          [ 0.0703, -0.0666, -0.0356],\n",
      "          [ 0.0780, -0.0105,  0.0735]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0845, -0.0697,  0.0610],\n",
      "          [-0.0289,  0.0870,  0.0798],\n",
      "          [ 0.0921,  0.0498,  0.0253]],\n",
      "\n",
      "         [[-0.0434, -0.0248, -0.0813],\n",
      "          [-0.0071,  0.0846,  0.0199],\n",
      "          [-0.0501,  0.0638,  0.0908]],\n",
      "\n",
      "         [[ 0.0386,  0.0617, -0.0637],\n",
      "          [-0.0724,  0.0706,  0.0104],\n",
      "          [-0.0103, -0.0263,  0.0330]]],\n",
      "\n",
      "\n",
      "        [[[-0.0258, -0.0514,  0.0275],\n",
      "          [-0.0097, -0.0662, -0.0273],\n",
      "          [ 0.0107,  0.0314, -0.0309]],\n",
      "\n",
      "         [[-0.0902,  0.0680,  0.0546],\n",
      "          [ 0.0526, -0.0242,  0.0397],\n",
      "          [-0.0363,  0.0499, -0.0986]],\n",
      "\n",
      "         [[-0.0898, -0.0200, -0.0194],\n",
      "          [-0.0342, -0.0548, -0.0547],\n",
      "          [-0.0927,  0.0312, -0.0354]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0332, -0.0016, -0.0139],\n",
      "          [-0.0684, -0.0915,  0.0413],\n",
      "          [-0.0530,  0.0172, -0.0966]],\n",
      "\n",
      "         [[ 0.0196,  0.0416, -0.0111],\n",
      "          [-0.0525,  0.0177,  0.0488],\n",
      "          [ 0.0776,  0.0796, -0.1042]],\n",
      "\n",
      "         [[-0.0736,  0.0461,  0.0821],\n",
      "          [-0.1003, -0.0749,  0.0332],\n",
      "          [-0.0048,  0.0392,  0.0255]]]], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for k, v in model_2.GRU.named_aprameters():\n",
    "    print(k)\n",
    "    print(v)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f1a3ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn.backbone.0.weight\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0486,  0.0118,  0.0707],\n",
      "          [-0.0283, -0.0692, -0.0120],\n",
      "          [-0.0295,  0.0435, -0.0595]],\n",
      "\n",
      "         [[ 0.0745, -0.0813, -0.0288],\n",
      "          [-0.0341, -0.0593, -0.0925],\n",
      "          [-0.0449, -0.0045,  0.0797]],\n",
      "\n",
      "         [[ 0.0111, -0.0546,  0.0928],\n",
      "          [-0.0002,  0.0918,  0.0546],\n",
      "          [ 0.0231,  0.0503, -0.0050]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0634,  0.0024,  0.0605],\n",
      "          [ 0.0268,  0.0479, -0.0075],\n",
      "          [-0.0567, -0.0272,  0.0724]],\n",
      "\n",
      "         [[ 0.0393, -0.0100,  0.0330],\n",
      "          [ 0.0842,  0.0405,  0.0494],\n",
      "          [-0.0776,  0.0354, -0.0375]],\n",
      "\n",
      "         [[-0.0200,  0.0391,  0.0824],\n",
      "          [-0.0059,  0.0363, -0.0311],\n",
      "          [ 0.0870, -0.0655,  0.0763]]],\n",
      "\n",
      "\n",
      "        [[[-0.0397, -0.0686, -0.0313],\n",
      "          [ 0.0567, -0.0200,  0.0830],\n",
      "          [-0.0130,  0.0776,  0.0951]],\n",
      "\n",
      "         [[ 0.0681, -0.0171,  0.0111],\n",
      "          [-0.0760, -0.0411,  0.0436],\n",
      "          [ 0.0628, -0.0152, -0.0196]],\n",
      "\n",
      "         [[ 0.0104,  0.0266,  0.0270],\n",
      "          [ 0.0528, -0.0667,  0.0202],\n",
      "          [-0.0508, -0.0686,  0.0384]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0293, -0.0942, -0.0918],\n",
      "          [-0.0135, -0.0685,  0.0966],\n",
      "          [ 0.0265, -0.0217,  0.0501]],\n",
      "\n",
      "         [[-0.0764,  0.0721,  0.0562],\n",
      "          [-0.0151,  0.0765, -0.0237],\n",
      "          [-0.0575,  0.0456, -0.0425]],\n",
      "\n",
      "         [[-0.0164, -0.0519, -0.0405],\n",
      "          [ 0.0727,  0.0095,  0.0284],\n",
      "          [-0.0374,  0.0769,  0.0730]]],\n",
      "\n",
      "\n",
      "        [[[-0.0872,  0.0696,  0.0350],\n",
      "          [ 0.0350, -0.0389,  0.0949],\n",
      "          [-0.0209, -0.0379,  0.0014]],\n",
      "\n",
      "         [[-0.0097, -0.0288, -0.0015],\n",
      "          [ 0.0476, -0.0568, -0.0130],\n",
      "          [ 0.0889, -0.0616, -0.0676]],\n",
      "\n",
      "         [[ 0.0651, -0.0923,  0.0756],\n",
      "          [-0.0490, -0.0290, -0.0694],\n",
      "          [ 0.0753, -0.0026, -0.0891]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0214, -0.0376,  0.0906],\n",
      "          [-0.0278,  0.0553,  0.0185],\n",
      "          [ 0.0038, -0.0535,  0.0467]],\n",
      "\n",
      "         [[ 0.0890,  0.0045,  0.0834],\n",
      "          [ 0.0855,  0.0124,  0.0610],\n",
      "          [ 0.0067, -0.0693, -0.0748]],\n",
      "\n",
      "         [[-0.0921,  0.0216,  0.0911],\n",
      "          [-0.0739,  0.0335, -0.0268],\n",
      "          [ 0.0387,  0.0910,  0.0637]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0844,  0.0761,  0.0628],\n",
      "          [ 0.0142, -0.0121,  0.0360],\n",
      "          [-0.0838,  0.0024,  0.0255]],\n",
      "\n",
      "         [[ 0.0251, -0.0917,  0.0065],\n",
      "          [ 0.0732, -0.0087, -0.0625],\n",
      "          [ 0.0299,  0.0252, -0.0673]],\n",
      "\n",
      "         [[-0.0536, -0.0661,  0.0326],\n",
      "          [ 0.0441, -0.0848, -0.0311],\n",
      "          [ 0.0219, -0.0064, -0.0782]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0317, -0.0348, -0.0950],\n",
      "          [ 0.0852, -0.0625, -0.0909],\n",
      "          [ 0.0669, -0.0351, -0.0351]],\n",
      "\n",
      "         [[-0.0387,  0.0526,  0.0036],\n",
      "          [ 0.0339, -0.0741,  0.0242],\n",
      "          [ 0.0456, -0.0668, -0.0899]],\n",
      "\n",
      "         [[ 0.0730, -0.0146, -0.0267],\n",
      "          [ 0.0183, -0.0080,  0.0907],\n",
      "          [ 0.0395, -0.0146, -0.0668]]],\n",
      "\n",
      "\n",
      "        [[[-0.0404,  0.0733, -0.0122],\n",
      "          [ 0.0660, -0.0341,  0.0554],\n",
      "          [-0.0450, -0.0690,  0.0366]],\n",
      "\n",
      "         [[ 0.0693, -0.0614, -0.0832],\n",
      "          [-0.0222,  0.0762,  0.0272],\n",
      "          [ 0.0162,  0.0398,  0.0311]],\n",
      "\n",
      "         [[ 0.0893, -0.0393, -0.0009],\n",
      "          [ 0.0778, -0.0604, -0.0283],\n",
      "          [ 0.0833, -0.0046,  0.0798]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0811, -0.0724,  0.0570],\n",
      "          [-0.0318,  0.0818,  0.0756],\n",
      "          [ 0.0862,  0.0439,  0.0194]],\n",
      "\n",
      "         [[-0.0479, -0.0285, -0.0862],\n",
      "          [-0.0103,  0.0788,  0.0154],\n",
      "          [-0.0564,  0.0574,  0.0847]],\n",
      "\n",
      "         [[ 0.0330,  0.0566, -0.0693],\n",
      "          [-0.0763,  0.0641,  0.0057],\n",
      "          [-0.0173, -0.0333,  0.0267]]],\n",
      "\n",
      "\n",
      "        [[[-0.0241, -0.0498,  0.0293],\n",
      "          [-0.0079, -0.0645, -0.0257],\n",
      "          [ 0.0127,  0.0331, -0.0291]],\n",
      "\n",
      "         [[-0.0877,  0.0703,  0.0572],\n",
      "          [ 0.0552, -0.0218,  0.0419],\n",
      "          [-0.0334,  0.0523, -0.0961]],\n",
      "\n",
      "         [[-0.0866, -0.0169, -0.0162],\n",
      "          [-0.0310, -0.0517, -0.0520],\n",
      "          [-0.0893,  0.0343, -0.0323]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0274,  0.0048, -0.0065],\n",
      "          [-0.0629, -0.0854,  0.0478],\n",
      "          [-0.0483,  0.0227, -0.0897]],\n",
      "\n",
      "         [[ 0.0233,  0.0464, -0.0056],\n",
      "          [-0.0490,  0.0227,  0.0537],\n",
      "          [ 0.0798,  0.0834, -0.0970]],\n",
      "\n",
      "         [[-0.0688,  0.0495,  0.0867],\n",
      "          [-0.0958, -0.0707,  0.0370],\n",
      "          [-0.0027,  0.0416,  0.0318]]]], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for k, v in model.GRU.named_parameters():\n",
    "    print(k)\n",
    "    print(v)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbd8f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = (torch.sigmoid(logits) > 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68a4351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "289f5016",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/3000 [00:00<32:43,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n",
      "tensor(1., device='cuda:0')\n",
      "torch.Size([1, 10])\n",
      "tensor(0., device='cuda:0')\n",
      "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "torch.Size([1, 12, 64, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/3000 [00:03<3:11:19,  3.83s/it]\n"
     ]
    }
   ],
   "source": [
    "for video, labels in tqdm(train_loader):\n",
    "    video = video.to(device)\n",
    "    labels = labels.to(device)\n",
    "    cnt += 1\n",
    "    print(labels.shape)\n",
    "    print(labels[0][0])\n",
    "    if int(labels[0][1]) == 0:\n",
    "        continue\n",
    "    print(labels)\n",
    "    video = model.autoregressive_sample(c=labels, autoregressive_steps=5, img_wh=[64, 64], x_p=video[:,:12])\n",
    "    break\n",
    "    # video = model.autoregressive_sample(c=labels, autoregressive_steps=5, img_wh=[256, 256], x_p=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99c2bddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 72, 1, 64, 64])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e466ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_video = video.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe4b0786",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(copy_video.shape[1]):  # 遍历每一帧\n",
    "    # 对每帧应用softmax使像素互相竞争\n",
    "    frame = copy_video[:, t].reshape(1, -1)  # 将形状变为 (1, 256*256)\n",
    "    softmax_frame = torch.softmax(frame, dim=1)\n",
    "    \n",
    "    # 归一化处理，让值分布更均匀\n",
    "    # 将最大值缩放到接近1.0，使二值化有意义\n",
    "    min_val = softmax_frame.min()\n",
    "    max_val = softmax_frame.max()\n",
    "    if max_val > min_val:  # 避免除零错误\n",
    "        normalized = (softmax_frame - min_val) / (max_val - min_val)\n",
    "        copy_video[:, t] = normalized.reshape(copy_video[:, t].shape)\n",
    "    else:\n",
    "        copy_video[:, t] = softmax_frame.reshape(copy_video[:, t].shape)\n",
    "copy_video = (copy_video > 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce28051f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIF 已保存为 'animation_5_add_1st_chunk.gif'\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "# 将视频数据转移到 CPU 并转换为 numpy 数组\n",
    "video_np = copy_video[:,12:].cpu().detach().numpy()\n",
    "\n",
    "# 假设视频形状为 [batch, autoregressive_steps, time_step, channels, height, width]\n",
    "# 展平多个维度以获得总共 60 帧\n",
    "flat_video = video_np.reshape(-1, *video_np.shape[-3:])  # [total_frames, channels, height, width]\n",
    "\n",
    "# 如果帧数不足 60，可以循环播放以达到 60 帧\n",
    "frames = []\n",
    "total_frames = flat_video.shape[0]\n",
    "repeats = max(1, int(np.ceil(60 / total_frames)))\n",
    "\n",
    "for _ in range(repeats):\n",
    "    for i in range(total_frames):\n",
    "        if len(frames) >= 60:\n",
    "            break\n",
    "            \n",
    "        # 获取当前帧并去掉通道维度（如果为1）\n",
    "        frame = flat_video[i, 0] if flat_video.shape[1] == 1 else flat_video[i].transpose(1, 2, 0)\n",
    "        \n",
    "        # 缩放到 [0, 255] 范围并转换为 uint8\n",
    "        frame = (frame * 255).astype(np.uint8)\n",
    "        frames.append(frame)\n",
    "\n",
    "# 创建 GIF\n",
    "imageio.mimsave('animation_20_0505_400k_32_unet_cat_1k.gif', frames, fps=10)\n",
    "print(\"GIF 已保存为 'animation_5_add_1st_chunk.gif'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9466d288",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UnSAM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
